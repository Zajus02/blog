---
layout: post
title: The age of content
date: 2024-08-26
last_modified_at: 2024-09-09
categories: Technology
tags:
---

It is in the nature of children to desire the most advanced and exciting toys possible. I vaguely remember that when I was seven, someone showed me their PlayStation (the first generation), and I was amazed by the games it could play. After much begging (that may have taken several years), I finally got my own game console, and even today, I remember every corner of some of the tracks in Gran Turismo 2.

Around the same time, a neighbor of mine was given a PC, a very old one with MS-DOS and a bunch of floppy disks containing simple 2D games. In comparison to my brand-new PlayStation, this was prehistory. But somehow, the more opportunities I had to explore the functions of that old PC, the more interested I became. With PlayStation, you could play games, which was surely fun, but also somewhat limited. In contrast, the `PC was complicated to use and the games were far from realistic, but the possibilities were practically endless`. I didn’t throw my PlayStation away, but it became clear that what I truly wanted was a PC.

It didn't take long before I had one, and with it came another novelty: the Internet. In 2001, the Internet was already booming (or busting, depending on who you ask), but if I were to describe it in one word, it would be "static". Posting something online is simple today, but back in the early years of the third millennium, before social networks and WordPress, you couldn’t just open a browser window and share whatever you wanted with the world. You had to go the hard way. Yet, it wasn’t rocket science. Anyone even slightly curious could figure out how to do it by simply opening the source code of any website and studying its guts. PlayStation games were entertaining, and PC games even more so, but both paled in comparison to the Internet, the endless pool where you didn’t just consume. You could also create.

The rest of the story might be quite obvious. After trying to figure out how websites worked, the next step was to create one from scratch. First, there were the WYSIWYG editors. I remember creating simple websites (probably about computer games) using Microsoft FrontPage. Quite quickly, the limitations of this method became clear, leading me to learn how to code in HTML. This was far more complicated, at least for the brain of a twelve-year-old, but also much more rewarding. However, pure HTML websites were ugly and the solution, CSS, was newly accepted as the right way to style websites. Simultaneously, static websites were being replaced by something much more awesome: dynamic sites, with possibilities growing exponentially. Java? Flash? PHP? Naturally, I had to explore everything, so while my peers wished for new computer games (or bikes, in the case of the weirdos), I always begged my parents to buy me a new book about whichever technology I was currently exploring. I’m not saying I didn’t want a bike and games as well, but my desires were broader. I wanted to create, and to be able to create, I first needed to know how.

In the end, I never learned any programming language well enough to make a living from it, partially because I was told I wasn’t smart enough to do so (more on that some other time). But still, all those years spent fooling around with (now often dead and useless) technologies gave me a solid background, which turned out to be useful on many occasions. And all that was, in fact, fun. Nobody forced me; nobody in my surroundings even understood what I was trying to achieve. Without any external push, I spent countless hours doing something most kids considered boring and most adults would call work. Later in life, I benefited from it—not directly by monetizing these skills, but indirectly by absorbing something from each of them. 

So how was this passion born? I believe two conditions had to be fulfilled:
1. Achieving results must be simple enough.
2. The first condition must be obvious enough for you to see.

First, `you cannot get excited about doing something so incredibly complex that it obscures your mind`, making it impossible to see the end of it. That was the case with websites in the early 2000s. They were primitive, created using simple code that was largely understandable without any formal training. It didn’t take a genius to imagine that you could create something like that. The websites of 2001 were also scalable. From a set of very simple components, you could build something complex. When one technology didn’t do what you wanted, there was always another one lurking around the corner, just slightly more complex than the one you already knew. This made things much easier to digest.

Second, it is necessary for the initial spark to arrive. It is much easier to pick up a book and learn something if you already understand a little about how it works. This was again true for websites, because it was so simple to see the code behind any one you visited.

In essence, the accumulation of knowledge works like building a Lego set. Whenever you see something made of Lego, you can immediately observe the individual blocks and how they are connected. You can take it apart, grab another set of Lego blocks, and try to recreate it or start by building a simpler version. One block adds to another, and in a couple of hours, you have a detailed copy of the Taj Mahal standing in your living room.

Once the general rule is known, it becomes clear that my generation wasn’t the only one benefiting from such a possibility. There is always something, and finding out what it is might only seem complicated when looking backward because, at the time, these opportunities were obvious. To make things simpler, let’s stick to examples within the IT world. Just a generation before mine, there were no websites, but that doesn’t mean there was nothing for young minds to get excited about. In the time of Amiga, Apple II, early PCs, and the like, it was much more apparent that software was made out of blocks of code. And since these programs and games were often the first of their kind, they were simple enough to be understood with some effort, making it easy to imagine creating something of your own. In other words, condition number one applied. On top of that, there was often no graphical user interface to hide the bare code, so we know that condition number two (the "in-your-face effect," as I’d like to call it) applied as well.

This also explains why, in my generation, very few kids started their programming careers by creating games. By then, games were already incredibly complex and hid their code as much as possible. No twelve-year-old played a PlayStation game and thought: "I could create something like that." They may have ended up creating PlayStation games eventually, but they definitely started somewhere else, where the bar was much lower, such as Flash games played in the browser.

So how about the generation before? There were probably several options, but if I had to guess which was the major one, I’d name electronic circuits and simple logic. There were hardware-level programming languages at the time, but to get excited about one, you first needed to see it in practice and be blown away by the results. However, the results of the computers of those days were too abstract and too distant for ordinary people to see.

But what is the "thing" today? What are the future IT experts excited about? How will this affect their future? I don't want to be a doomsayer, but in a way, I believe this window of opportunity is now closing, or at least shifting to other fields. The trend today is simplification, achieving the same results with a more straightforward process. Nassim Nicholas Taleb said that a tablet as a device is something one can operate much more instinctively than a PC, using fingers instead of a mouse-shaped, artificially created device. The ape inside him knows how to use the tablet, and children can use it without being taught how. `A tablet can do 90% of what an ordinary user expects from a PC, but with much less effort needed to understand how things work. This becomes a problem for the hackers of the future.`

PCs are buggy, and when you try to do something, you're often halted by errors and failures. But when you really want to achieve something, you can dig in and overcome the issue by figuring out where the problem lies. This urges you to understand how things work. However, as today's technologies become more and more idiot-resistant and the number of visible errors decreases (both of which are good things!), you also lose the chance to learn by fixing problems. Because the number of hardware and software combinations within tablets and mobile phones (including the excessive variety of Android devices) is much smaller than the number of combinations in PCs, you are less likely to stumble upon an error you can solve. When I couldn't launch a PC game, I spent hours figuring out where the problem was and how to solve it, and often I succeeded. When a game on a tablet doesn't work, there's next to nothing you can do—apart from buying a new device.

As technology advances, conditions one and two are becoming less true. `The programming behind current devices is incredibly complex and, at the same time, hidden from view.` Kids today cannot see what is behind the user interface, and even if they could, they would be scared by its complexity. This doesn't mean that once the PC generation ages, we will run out of new programmers. Instead, the IT experts of the future will probably get excited later in life when they can grasp more complicated structures without being overwhelmed. Additionally, the PC isn’t dead yet, and some will definitely be intrigued by its faults and possibilities, even though others may jump from browsing websites on a tablet straight to playing games on Xbox without even thinking about what lies behind what they see.

The geek inside me isn't thrilled about this, but I believe it’s ultimately a good thing. Instead of focusing on how things work, the kids of today and the future will be able to focus on something else: doing the things that the tools they use are supposed to do. Here, the possibilities are endless. With young creators of simple games or websites, the problem was that to create a little bit of content, they had to create large supporting structures—the code behind the slick UI. The sentence "Hello, my name is John" takes up one line of code, but the surroundings, even on a plain website containing nothing else, will take up nine more. In terms of the number of lines, to create one line of content, you had to create ten lines in total. If you wanted to share something more complex, the amount of code could grow exponentially. But today? If you want to share that your name is John, you simply choose one of the numerous websites and type that your name is John. Job done, congratulations. Maybe you learned nothing in the process, but it was effortless, and next time, you might consider writing something longer, like a story.

And this is just one of a million possibilities. If you like a video you see on YouTube, you can immediately start recreating, expanding, or parodying it, usually with the same $200 device you used to watch the video in the first place. Do you like a song? Download one of countless music-making apps and see if you can create a similar one. How about a picture? Well, yes, paint a new Mona Lisa if you want—you can even use your fingers instead of a brush. Again, the possibilities are endless.

You may object that no great movies were filmed, no great songs composed, and no great paintings created on an iPad. Maybe, but that time is getting closer. Serj Tankian, an accomplished artist, composed one of his albums using an iPad in 2012. The album wasn’t great, but I wouldn’t blame the iPad. Additionally, this is just the first step. Do you enjoy creating YouTube videos using your iPad and want an upgrade? Sure thing, you already know what you need. It’s the same process as with young hackers—step by step, you become proficient at something, acquiring the necessary skills and equipment along the way.

`We are entering the age of content`, an era in which, if you want to share something with the world, you don't have to overcome any IT obstacles. It’s exciting and frightening at the same time. It has the power to change people's lives. What you do at thirteen doesn’t define your entire future, but it can give you a hint and help build a foundation you can use for many years to come. Whether you end up as a florist with a passion for and understanding of filmmaking or a salesperson with an IT background might not matter at all in the end. But it could.

*Originally written circa 2013. Slightly revised in 2024.*
